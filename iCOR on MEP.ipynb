{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iCOR on MEP notebook\n",
    "This notebook shows how to use iCOR on the MEP platform via a Jupyter notebook. The input products must be made available on the MEP platform. Processing is done on the Hadoop cluster of the MEP platform and the outputs are made available under your MEP private folder (/data/users/Private/<username>/icor_results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: specify the input products\n",
    "These input products can be either in your Probav-V MEP Public or Private folder (https://proba-v-mep.esa.int/documentation/manuals/how-get-data-mep), because they need to be accessible from the Hadoop processing nodes. Change the defaults provided below to process your own input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = ['/data/users/Private/daemsd/icor_input/S2A_20170527T102031_T33UUB_20170527T102301.SAFE/MTD_MSIL1C.xml',\n",
    "           '/data/users/Private/daemsd/icor_input/S2A_20170822T101031_T32TQN_20170822T101057.SAFE/MTD_MSIL1C.xml']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: specify iCOR parameters\n",
    "Specify the iCOR parameters, change them if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "icor_params = {\n",
    "  # input data type: 'S2' or 'L8'\n",
    "  \"data_type\" : 'S2',\n",
    "  # band to apply cloud low threshold (zero based): 'B01','B02','B03','B04','B05','B06','B07','B08','B8A','B09','B10','B11' or 'B12'\n",
    "  \"low_band\" : 'B01',\n",
    "  # water detection band id (zero based): 'B01','B02','B03','B04','B05','B06','B07','B08','B8A','B09','B10','B11' or 'B12'\n",
    "  \"water_band\" : 'B08',\n",
    "  # water detection threshold\n",
    "  \"water_threshold\" : '0.05',\n",
    "  # upper threshold with average in the visual bands to be detected as cloud. Range 0.0 .. 1.0.\n",
    "  \"average_threshold\" : '0.19',\n",
    "  # low band threshold to be detected as cloud. Range 0.0 .. 1.0.\n",
    "  \"low_threshold\" : '0.25',\n",
    "  # apply AOT retrieval algorithm\n",
    "  \"aot\" : 'true',\n",
    "  # square window size in pixels to perform aot estimation\n",
    "  \"aot_window_size\" : '100',\n",
    "  # AOT override values\n",
    "  \"aot_override\" : '0.1',\n",
    "  # use cirrus band for cloud detection: true or false\n",
    "  \"cirrus\" : 'true',\n",
    "  # cloud mask threshold value. Range 0.0 .. 1.0\n",
    "  \"cirrus_threshold\" : '0.01',\n",
    "  # apply adjacency correction: true or false\n",
    "  \"simec\" : 'true',\n",
    "  # apply watervapor estimation: true or false\n",
    "  \"watervapor\" : 'false',\n",
    "  # WATERVAPOR override value. Range 0.0 .. 5.0.\n",
    "  \"watervapor_override\" : '0.1',\n",
    "  # default background window size\n",
    "  \"bg_window\" : '1',\n",
    "  # OZONE override values\n",
    "  \"ozone_override\" : '0.33',\n",
    "  \"keep_intermediate\" : \"false\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3: setup iCOR\n",
    "This step creates a method which will be used to apply iCOR on each input product. Normally, you should not change the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_product(product, params):\n",
    "    \n",
    "    import ConfigParser\n",
    "    import logging\n",
    "    import icor.landsat8\n",
    "    import icor.sentinel2\n",
    "    import getpass\n",
    "    import os, errno\n",
    "    import traceback\n",
    "\n",
    "    # setup logging\n",
    "    logger = logging.getLogger(\"py4j\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    # avoid adding multiple handlers which would cause one message to be printed multiple times\n",
    "    logger.handlers[0] = logging.StreamHandler()\n",
    "\n",
    "    logging.root = logger\n",
    "    logging.Logger.manager.root = logger\n",
    "\n",
    "    conf = ConfigParser.SafeConfigParser()\n",
    "    try:\n",
    "        icor_dir = str(os.environ['ICOR_DIR'])\n",
    "        logger.info('Using iCOR dir %s', icor_dir)\n",
    "    except Exception:\n",
    "        icor_dir = '/data/icor/v1.0.0'\n",
    "        os.environ['ICOR_DIR'] = icor_dir\n",
    "        logger.info('Using default iCOR dir %s', icor_dir)\n",
    "\n",
    "    # set GDAL data dir, otherwise images are not projected\n",
    "    os.environ['GDAL_DATA'] = '/opt/gdal2/share/gdal'\n",
    "\n",
    "    conf.set(\"DEFAULT\", \"install_dir\", icor_dir)\n",
    "\n",
    "    if icor_params.get(\"data_type\") == \"L8\":\n",
    "        conf.read(icor_dir + \"/src/config/local_landsat8_simec.ini\")\n",
    "    elif icor_params.get(\"data_type\") == \"S2\":\n",
    "        conf.read(icor_dir + \"/src/config/local_sentinel2_simec.ini\")\n",
    "\n",
    "    parent_output_dir = \"/data/users/Private/\" + getpass.getuser() + \"/icor_results/\"\n",
    "    try:\n",
    "        os.makedirs(parent_output_dir)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "    product_name = os.path.basename(os.path.dirname(product))\n",
    "    output_dir = os.path.join(parent_output_dir, product_name)\n",
    "            \n",
    "    params[\"keep_intermediate\"] = \"false\"\n",
    "    params[\"output_file\"] = output_dir\n",
    "\n",
    "    # convert to params for context\n",
    "    context = icor.context.SimpleContext(params, logger=logger)\n",
    "\n",
    "    for param, value in conf.items(\"DEFAULT\"):\n",
    "        params[param] = value\n",
    "\n",
    "    for section in conf.sections():\n",
    "        for param, value in conf.items(section):\n",
    "            params[section + \"_\" + param] = value\n",
    "\n",
    "    try:\n",
    "        working_folder = os.getcwd()\n",
    "        if context[\"instrument\"] == \"landsat8\":\n",
    "            if context[\"workflow\"] == \"simec\":\n",
    "                icor.landsat8.process_tgz(context, product, working_folder)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown 'instrument'\")\n",
    "        elif context[\"instrument\"] == \"sentinel2\":\n",
    "            if context[\"workflow\"] == \"simec\":\n",
    "                icor.sentinel2.process_tar(context, product, working_folder)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown 'instrument'\")\n",
    "        else:\n",
    "            raise ValueError(\"Unknown 'workflow'\")\n",
    "            \n",
    "        return output_dir\n",
    "    except:\n",
    "        logger.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4: initialize Spark and start the job\n",
    "This step will first initialize the Spark context and then start the job. Of course, this can take a while, depending on the number of products you would like to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files can be found here:\n",
      "\n",
      "['/data/users/Private/daemsd/icor_results/S2A_20170527T102031_T33UUB_20170527T102301.SAFE', '/data/users/Private/daemsd/icor_results/S2A_20170822T101031_T32TQN_20170822T101057.SAFE']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SparkContext' object has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-323c32ca43b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparkContext' object has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# Setup the Spark cluster\n",
    "conf = SparkConf()\n",
    "conf.set('spark.yarn.executor.memoryOverhead', 1024)\n",
    "conf.set('spark.executor.memory', '6g')\n",
    "conf.set('spark.executor.cores', '1')\n",
    "conf.set('spark.executor.instances', 2)\n",
    "\n",
    "sc = SparkContext(appName='icor-mep', conf=conf)\n",
    "\n",
    "try:  \n",
    "    productsRDD = sc.parallelize(products)\n",
    "    outputs = productsRDD.map(lambda product: process_product(product, icor_params)).collect()\n",
    "    print 'Output files can be found here:\\n'\n",
    "    print outputs\n",
    "finally:\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
